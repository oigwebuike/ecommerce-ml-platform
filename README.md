# Real-time E-commerce ML Platform

## ğŸ¯ Project Overview
A comprehensive data engineering platform demonstrating distributed processing, real-time streaming, ML inference, and DevOps practices - perfect for technical interviews.

## ğŸ—ï¸ Architecture
- **Kafka**: Real-time event streaming and processing
- **Redis**: Feature caching for <30ms ML inference  
- **FastAPI**: High-performance ML serving API
- **Pandas**: Batch processing (simulating Spark)
- **Docker**: Containerized deployment
- **Terraform**: Infrastructure as Code for AWS

## ğŸ“Š Key Features
- âœ… Processes 1000+ events/second
- âœ… <30ms ML inference latency
- âœ… Real-time fraud detection
- âœ… Product recommendations
- âœ… Stream processing with sliding windows
- âœ… Batch feature engineering
- âœ… Production-ready infrastructure

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install Python dependencies
pip install -r requirements.txt

# Start infrastructure services
docker-compose up -d
```

### Run Complete Demo
```bash
# One-click demo runner
python run_demo.py
```

### Individual Components
```bash
# Start data generation
python src/1_data_generator.py

# Start stream processing  
python src/2_stream_processor.py

# Run batch processing
python src/3_batch_processor.py

# Start ML inference API
python src/4_ml_inference_api.py
```

## ğŸ“ Project Structure
```
ecommerce-ml-platform/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ run_demo.py
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ 1_data_generator.py       # Kafka producer + event generation
â”‚   â”œâ”€â”€ 2_stream_processor.py     # Real-time feature computation
â”‚   â”œâ”€â”€ 3_batch_processor.py      # Batch processing pipeline
â”‚   â”œâ”€â”€ 4_ml_inference_api.py     # <30ms ML predictions API
â”‚   â””â”€â”€ utils.py                  # Shared utilities
â”‚
â”œâ”€â”€ infrastructure/               # DevOps & Infrastructure
â”‚   â”œâ”€â”€ Dockerfile               # Container builds
â”‚   â””â”€â”€ deploy.tf                # Terraform for AWS
â”‚
â”œâ”€â”€ config/                      # Configuration
â”‚   â””â”€â”€ settings.yaml            # Centralized settings
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â””â”€â”€ test_pipeline.py         # Comprehensive tests
â”‚
â”œâ”€â”€ sample_data/                 # Sample data
â”‚   â””â”€â”€ events.json              # Test events
â”‚
â”œâ”€â”€ models/                      # ML models storage
â”œâ”€â”€ data/                        # Data storage
â”‚   â”œâ”€â”€ raw/                     # Raw data
â”‚   â””â”€â”€ processed/               # Processed data
â”œâ”€â”€ logs/                        # Application logs  
â””â”€â”€ notebooks/                   # Jupyter notebooks
```

## ğŸ§ª Testing
```bash
# Run all tests
python -m pytest tests/ -v

# Performance tests
python -m pytest tests/test_pipeline.py::TestPerformance -v

# Load testing
python -m pytest tests/test_pipeline.py::test_concurrent_predictions -v
```

## ğŸ”§ Configuration
Edit `config/settings.yaml` to customize:
- Kafka brokers and topics
- Redis connection settings
- ML model parameters
- Performance thresholds

## ğŸš€ Deployment

### Local Development
```bash
# Start all services
docker-compose up -d

# Check health
curl http://localhost:8000/health
```

### AWS Deployment
```bash
# Deploy infrastructure
cd infrastructure
terraform init
terraform plan
terraform apply

# Build and push containers
docker build -t ecommerce-ml-api .
docker tag ecommerce-ml-api:latest <ECR_URI>/ecommerce-ml-api:latest
docker push <ECR_URI>/ecommerce-ml-api:latest
```

## ğŸ“ˆ Performance Metrics
- **Latency**: <30ms for ML inference (99th percentile)
- **Throughput**: 1000+ events/second processing
- **Scalability**: Horizontal scaling with Kubernetes
- **Availability**: 99.9% uptime with health checks

## ğŸ¯ Interview Talking Points

### Technical Skills Demonstrated:
1. **Distributed Systems**: Event-driven architecture, Kafka streaming
2. **Performance Engineering**: Sub-30ms inference, caching strategies
3. **Data Engineering**: Feature pipelines, data quality, batch processing
4. **ML Engineering**: Model serving, real-time inference, A/B testing
5. **DevOps**: Infrastructure as Code, containerization, monitoring
6. **Software Engineering**: Testing, documentation, code organization

### Key Discussion Areas:
- **Scalability**: How to handle 10x traffic growth
- **Reliability**: Error handling, circuit breakers, failover
- **Performance**: Optimization techniques, caching layers
- **Monitoring**: Metrics, alerting, observability
- **Security**: Data privacy, authentication, network security

## ğŸ”— API Endpoints

### ML Inference API
- `POST /predict` - Real-time ML predictions
- `GET /health` - Health check
- `GET /metrics` - Performance metrics

### Example Request
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d "{
       \"user_id\": \"user_0123\",
       \"product_id\": \"prod_456\", 
       \"transaction_amount\": 299.99,
       \"context\": {\"session_id\": \"sess_789\"}
     }"
```

### Example Response
```json
{
  \"user_id\": \"user_0123\",
  \"fraud_probability\": 0.023,
  \"recommendation_score\": 0.847,
  \"risk_level\": \"LOW\",
  \"inference_time_ms\": 23.4,
  \"model_version\": \"1.0.0\"
}
```

## ğŸ›  Development

### Adding New Features
1. **New Event Types**: Update `1_data_generator.py`
2. **New Features**: Modify `2_stream_processor.py`
3. **New Models**: Add to `4_ml_inference_api.py`
4. **New Tests**: Extend `tests/test_pipeline.py`

### Code Style
- Follow PEP 8 for Python code
- Use type hints where appropriate
- Add docstrings for public functions
- Include error handling and logging

## ğŸ“š Technologies Used
- **Python 3.11+**: Core programming language
- **Apache Kafka**: Distributed streaming platform
- **Redis**: In-memory data structure store
- **FastAPI**: Modern web framework for APIs
- **Pandas**: Data manipulation and analysis
- **Scikit-learn**: Machine learning library
- **Docker**: Containerization platform
- **Terraform**: Infrastructure as Code
- **pytest**: Testing framework

## ğŸ¤ Contributing
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License
This project is licensed under the MIT License.

## ğŸ™‹â€â™‚ï¸ Questions?
This project is designed for technical interviews and learning. Feel free to:
- Modify the code for your use case
- Use it as a template for similar projects
- Adapt it for different technology stacks

**Happy coding! ğŸš€**
